Domain: Investment Banking and Insurance
Topic 1: Loading and Exploring DataFrames
DataSet: Day2_InvestmentBanking_LEDF.zip - 

Business Requirements:

1. Load client portfolio data from a CSV file and display the schema.
  - Business Need: Understand client portfolio details such as asset allocation, risk tolerance, and diversification.
2. Load transaction records from a JSON file and show the first 10 rows.
 - Business Need: Analyze recent client transactions for fraud detection and compliance.
3. Load stock price data from a partitioned Parquet file and filter data for a specific year.
 - Business Need: Extract stock performance data for a given year to identify trends.
4. Infer schema automatically for a CSV file, then display all column names.
 - Business Need: Validate and ensure data integrity in client portfolio data.
5. Explicitly define the schema for a JSON file and compare it with schema inference.
 - Business Need: Validate structured transaction data and compare inferred vs. expected structure.
6. Count the total number of rows in a Parquet file partitioned by year.
 - Business Need: Monitor annual trading volumes to assess market activity.
7. Find the maximum value in a specific column of a loaded CSV file.
 - Business Need: Identify the highest-value transactions for VIP clients.
8. Calculate the average transaction amount from JSON data.
 - Business Need: Understand typical transaction sizes across clients.
9. Load data from a CSV file and drop rows with null values.
 - Business Need: Clean incomplete client data before analysis.
10. Load data from a JSON file and fill null values with default values.
 - Business Need: Standardize incomplete data for transaction processing.
11. Load stock data from a partitioned Parquet file and perform a basic exploration (show, count, etc.).
 - Business Need: Perform exploratory analysis of stock performance.
12. Select specific columns from a DataFrame loaded from a CSV file.
 - Business Need: Focus on key attributes such as risk score and assets under management.
13. Filter rows from a JSON file where a column value meets a condition.
 - Business Need: Identify high-value withdrawals for compliance audits.
14. Create a summary (mean, median, max, min) of a column in a Parquet file.
 - Business Need: Summarize stock returns to assist investment decisions.
15. Load data from a CSV file and sort it by a specific column.
 - Business Need: Rank clients based on assets under management.
16. Count distinct values in a column from a DataFrame loaded from a JSON file.
 - Business Need: Determine the number of unique products offered in the insurance domain.
17. Perform sampling on a Parquet file and show the sampled rows.
 - Business Need: Extract a random sample of stock data for quick testing.
18. Repartition data from a CSV file into a specified number of partitions.
 - Business Need: Optimize data processing for distributed systems.
19. Group data loaded from a JSON file by a column and calculate aggregates.
 - Business Need: Calculate total transaction amounts grouped by client region.
20. Save a DataFrame loaded from a Parquet file into a new partitioned Parquet file.
 - Business Need: Reorganize stock data by year and sector for efficient querying.
===================================================================================
Topic 2: SQL Queries on DataFrames

DataSet: Day2_SQL_DF.zip - 

Business Requirements:

1. Register a CSV-loaded DataFrame as a temporary table and run a SELECT query.
 - Business Need: Extract key details from client portfolio data for reporting.
2. Perform an INNER JOIN on two JSON-loaded DataFrames and display results.
 - Business Need: Combine client transactions and product details to analyze sales patterns.
3. Use GROUP BY on a Parquet-loaded DataFrame to calculate totals.
 - Business Need: Compute total investment amounts grouped by product type.
4. Identify rows where a specific column value is null using SQL queries.
 - Business Need: Audit missing fields in client data for regulatory compliance.
5. Find the top 5 records with the highest values in a specific column.
 - Business Need: Identify top-performing advisors based on total sales.
6. Use CASE WHEN in a SQL query to categorize rows based on a column.
 - Business Need: Categorize clients into risk levels based on their portfolio composition.
7. Perform a LEFT JOIN between two DataFrames loaded from CSV and JSON files.
 - Business Need: Combine transaction data with client profiles, retaining all clients.
8. Create a TEMP VIEW for a DataFrame and query it with complex conditions.
 - Business Need: Analyze client investments filtered by region, risk, and investment type.
9. Perform UNION on two DataFrames loaded from Parquet files.
 - Business Need: Merge transaction data from two different regions for a global report.
10. Run a query to calculate the total and average values for a column grouped by another column.
 - Business Need: Calculate average transaction amounts for each product type.
11. Use SQL to find the number of unique values in a specific column.
 - Business Need: Identify the number of distinct products sold in an investment plan.
12. Write a SQL query to filter rows using multiple conditions.
  - Business Need: Identify transactions exceeding a specific threshold for high-risk products.
13. Perform a RIGHT JOIN between DataFrames and display unmatched rows.
  - Business Need: Find products with no associated transactions.
14. Create a derived column in SQL by performing arithmetic operations.
 - Business Need: Calculate projected returns for each client portfolio.
15. Query data from a temporary table with nested SQL queries.
 - Business Need: Generate a report of clients investing in specific high-yield products.
16. Perform an aggregation with multiple functions (SUM, AVG, COUNT) using SQL.
 - Business Need: Summarize client transactions by total, average, and count.
17. Write a SQL query to order data by a specific column in descending order.
 - Business Need: Rank advisors by total revenue generated.
18. Use SQL to calculate cumulative sums or running totals.
 - Business Need: Track cumulative transaction amounts for each client over time.
19. Delete duplicate rows in a DataFrame using SQL.
 - Business Need: Ensure no duplicate transactions in compliance reports.
20. Save the result of a SQL query into a new Parquet file.
 - Business Need: Export aggregated transaction summaries for archival.


========================================================================

Case Study: Wealth Management - Mis-Selling Detection
Business Requirement
A wealth management firm wants to:

Analyze client profiles, transaction records, and product data to detect potential mis-selling.
Integrate and query large datasets (100,000 rows) across CSV, JSON, and Parquet formats.
Perform various aggregations, joins, and filters to create actionable insights for regulatory compliance.

"Datasets used: client_portfolio.csv, transactions.json, product_data (partitioned Parquet)
# Step 2: Extract the ZIP File
zip_file_path = "/home/labuser/Downloads/product_data_partitioned.zip"  # Path to the ZIP file
extracted_dir = "/home/labuser/Downloads/extracted_parquet"  # Directory to extract Parquet files

# Unzip the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_dir)
print(f"Extracted Parquet files to: {extracted_dir}")
