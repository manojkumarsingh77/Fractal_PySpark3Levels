{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detected Schema:\n",
      "root\n",
      " |-- account_id: string (nullable = true)\n",
      " |-- transaction_amount: double (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "✅ Number of records in batch 0: 1\n",
      "✅ Number of records in batch 184: 1\n",
      "✅ Number of records in batch 1: 1\n",
      "✅ Number of records in batch 2: 1\n",
      "✅ Number of records in batch 3: 1\n",
      "✅ Number of records in batch 4: 1\n",
      "✅ Number of records in batch 5: 1\n",
      "✅ Number of records in batch 6: 1\n",
      "✅ Number of records in batch 7: 1\n",
      "✅ Number of records in batch 8: 1\n",
      "✅ Number of records in batch 9: 1\n",
      "✅ Number of records in batch 10: 1\n",
      "✅ Number of records in batch 11: 1\n",
      "✅ Number of records in batch 12: 1\n",
      "✅ Number of records in batch 13: 1\n",
      "✅ Number of records in batch 14: 1\n",
      "✅ Number of records in batch 15: 1\n",
      "✅ Number of records in batch 16: 1\n",
      "✅ Number of records in batch 17: 1\n",
      "✅ Number of records in batch 18: 1\n",
      "✅ Number of records in batch 19: 1\n",
      "✅ Number of records in batch 20: 1\n",
      "✅ Number of records in batch 21: 1\n",
      "✅ Number of records in batch 22: 1\n",
      "✅ Number of records in batch 23: 1\n",
      "✅ Number of records in batch 24: 1\n",
      "✅ Number of records in batch 25: 1\n",
      "✅ Number of records in batch 26: 1\n",
      "✅ Number of records in batch 27: 1\n",
      "✅ Number of records in batch 28: 1\n",
      "✅ Number of records in batch 29: 1\n",
      "✅ Number of records in batch 185: 0\n",
      "✅ Number of records in batch 30: 1\n",
      "✅ Number of records in batch 31: 1\n",
      "✅ Number of records in batch 32: 1\n",
      "✅ Number of records in batch 33: 1\n",
      "✅ Number of records in batch 34: 1\n",
      "✅ Number of records in batch 35: 1\n",
      "✅ Number of records in batch 36: 1\n",
      "✅ Number of records in batch 37: 1\n",
      "✅ Number of records in batch 38: 1\n",
      "✅ Number of records in batch 39: 1\n",
      "✅ Number of records in batch 40: 1\n",
      "✅ Number of records in batch 41: 1\n",
      "✅ Number of records in batch 42: 1\n",
      "✅ Number of records in batch 43: 1\n",
      "✅ Number of records in batch 44: 1\n",
      "✅ Number of records in batch 45: 1\n",
      "✅ Number of records in batch 46: 1\n",
      "✅ Number of records in batch 47: 1\n",
      "✅ Number of records in batch 48: 1\n",
      "✅ Number of records in batch 49: 1\n",
      "✅ Number of records in batch 50: 1\n",
      "✅ Number of records in batch 51: 1\n",
      "✅ Number of records in batch 52: 1\n",
      "✅ Number of records in batch 53: 1\n",
      "✅ Number of records in batch 54: 1\n",
      "✅ Number of records in batch 55: 1\n",
      "✅ Number of records in batch 56: 1\n",
      "✅ Number of records in batch 57: 1\n",
      "✅ Number of records in batch 58: 1\n",
      "✅ Number of records in batch 59: 1\n",
      "✅ Number of records in batch 60: 1\n",
      "✅ Number of records in batch 61: 1\n",
      "✅ Number of records in batch 62: 1\n",
      "✅ Number of records in batch 186: 1\n",
      "✅ Number of records in batch 63: 1\n",
      "✅ Number of records in batch 64: 1\n",
      "✅ Number of records in batch 65: 1\n",
      "✅ Number of records in batch 66: 1\n",
      "✅ Number of records in batch 67: 1\n",
      "✅ Number of records in batch 68: 1\n",
      "✅ Number of records in batch 69: 1\n",
      "✅ Number of records in batch 70: 1\n",
      "✅ Number of records in batch 71: 1\n",
      "✅ Number of records in batch 72: 1\n",
      "✅ Number of records in batch 73: 1\n",
      "✅ Number of records in batch 74: 1\n",
      "✅ Number of records in batch 75: 1\n",
      "✅ Number of records in batch 76: 1\n",
      "✅ Number of records in batch 77: 1\n",
      "✅ Number of records in batch 78: 1\n",
      "✅ Number of records in batch 79: 1\n",
      "✅ Number of records in batch 80: 1\n",
      "✅ Number of records in batch 81: 1\n",
      "✅ Number of records in batch 82: 1\n",
      "✅ Number of records in batch 83: 1\n",
      "✅ Number of records in batch 84: 1\n",
      "✅ Number of records in batch 85: 1\n",
      "✅ Number of records in batch 86: 1\n",
      "✅ Number of records in batch 87: 1\n",
      "✅ Number of records in batch 88: 1\n",
      "✅ Number of records in batch 89: 1\n",
      "✅ Number of records in batch 90: 1\n",
      "✅ Number of records in batch 91: 1\n",
      "✅ Number of records in batch 92: 1\n",
      "✅ Number of records in batch 93: 1\n",
      "✅ Number of records in batch 94: 1\n",
      "✅ Number of records in batch 95: 1\n",
      "✅ Number of records in batch 96: 1\n",
      "✅ Number of records in batch 187: 0\n",
      "✅ Number of records in batch 97: 1\n",
      "✅ Number of records in batch 98: 1\n",
      "✅ Number of records in batch 99: 1\n",
      "✅ Number of records in batch 100: 1\n",
      "✅ Number of records in batch 101: 1\n",
      "✅ Number of records in batch 102: 1\n",
      "✅ Number of records in batch 103: 1\n",
      "✅ Number of records in batch 104: 1\n",
      "✅ Number of records in batch 105: 1\n",
      "✅ Number of records in batch 106: 1\n",
      "✅ Number of records in batch 107: 1\n",
      "✅ Number of records in batch 108: 1\n",
      "✅ Number of records in batch 109: 1\n",
      "✅ Number of records in batch 110: 1\n",
      "✅ Number of records in batch 111: 1\n",
      "✅ Number of records in batch 112: 1\n",
      "✅ Number of records in batch 113: 1\n",
      "✅ Number of records in batch 114: 1\n",
      "✅ Number of records in batch 115: 1\n",
      "✅ Number of records in batch 116: 1\n",
      "✅ Number of records in batch 117: 1\n",
      "✅ Number of records in batch 118: 1\n",
      "✅ Number of records in batch 119: 1\n",
      "✅ Number of records in batch 120: 1\n",
      "✅ Number of records in batch 121: 1\n",
      "✅ Number of records in batch 122: 1\n",
      "✅ Number of records in batch 123: 1\n",
      "✅ Number of records in batch 124: 1\n",
      "✅ Number of records in batch 125: 1\n",
      "✅ Number of records in batch 126: 1\n",
      "✅ Number of records in batch 127: 1\n",
      "✅ Number of records in batch 128: 1\n",
      "✅ Number of records in batch 129: 1\n",
      "✅ Number of records in batch 130: 1\n",
      "✅ Number of records in batch 131: 1\n",
      "✅ Number of records in batch 188: 0\n",
      "✅ Number of records in batch 132: 1\n",
      "✅ Number of records in batch 133: 1\n",
      "✅ Number of records in batch 134: 1\n",
      "✅ Number of records in batch 135: 1\n",
      "✅ Number of records in batch 136: 1\n",
      "✅ Number of records in batch 137: 1\n",
      "✅ Number of records in batch 138: 1\n",
      "✅ Number of records in batch 139: 1\n",
      "✅ Number of records in batch 140: 1\n",
      "✅ Number of records in batch 141: 1\n",
      "✅ Number of records in batch 142: 1\n",
      "✅ Number of records in batch 143: 1\n",
      "✅ Number of records in batch 144: 1\n",
      "✅ Number of records in batch 145: 1\n",
      "✅ Number of records in batch 146: 1\n",
      "✅ Number of records in batch 147: 1\n",
      "✅ Number of records in batch 148: 1\n",
      "✅ Number of records in batch 149: 1\n",
      "✅ Number of records in batch 150: 1\n",
      "✅ Number of records in batch 151: 1\n",
      "✅ Number of records in batch 152: 1\n",
      "✅ Number of records in batch 153: 1\n",
      "✅ Number of records in batch 154: 1\n",
      "✅ Number of records in batch 155: 1\n",
      "✅ Number of records in batch 156: 1\n",
      "✅ Number of records in batch 157: 1\n",
      "✅ Number of records in batch 158: 1\n",
      "✅ Number of records in batch 159: 1\n",
      "✅ Number of records in batch 160: 1\n",
      "✅ Number of records in batch 161: 1\n",
      "✅ Number of records in batch 162: 1\n",
      "✅ Number of records in batch 163: 1\n",
      "✅ Number of records in batch 164: 1\n",
      "✅ Number of records in batch 165: 1\n",
      "✅ Number of records in batch 189: 0\n",
      "✅ Number of records in batch 166: 1\n",
      "✅ Number of records in batch 167: 1\n",
      "✅ Number of records in batch 168: 1\n",
      "✅ Number of records in batch 169: 1\n",
      "✅ Number of records in batch 170: 1\n",
      "✅ Number of records in batch 171: 1\n",
      "✅ Number of records in batch 172: 1\n",
      "✅ Number of records in batch 173: 1\n",
      "✅ Number of records in batch 174: 1\n",
      "✅ Number of records in batch 175: 1\n",
      "✅ Number of records in batch 176: 1\n",
      "✅ Number of records in batch 177: 1\n",
      "✅ Number of records in batch 178: 1\n",
      "✅ Number of records in batch 179: 1\n",
      "✅ Number of records in batch 180: 1\n",
      "✅ Number of records in batch 181: 1\n",
      "✅ Number of records in batch 182: 1\n",
      "✅ Number of records in batch 183: 1\n",
      "✅ Number of records in batch 184: 1\n",
      "✅ Number of records in batch 185: 1\n",
      "✅ Number of records in batch 186: 1\n",
      "✅ Number of records in batch 187: 1\n",
      "✅ Number of records in batch 188: 1\n",
      "✅ Number of records in batch 189: 1\n",
      "✅ Number of records in batch 190: 0\n",
      "✅ Number of records in batch 190: 0\n",
      "✅ Number of records in batch 191: 0\n",
      "✅ Number of records in batch 191: 0\n",
      "✅ Number of records in batch 192: 1\n",
      "✅ Number of records in batch 192: 1\n",
      "✅ Number of records in batch 193: 0\n",
      "✅ Number of records in batch 193: 0\n",
      "✅ Number of records in batch 194: 0\n",
      "✅ Number of records in batch 194: 0\n",
      "✅ Number of records in batch 195: 0\n",
      "✅ Number of records in batch 195: 0\n",
      "✅ Number of records in batch 196: 0\n",
      "✅ Number of records in batch 196: 0\n",
      "✅ Number of records in batch 197: 0\n",
      "✅ Number of records in batch 197: 1\n",
      "✅ Number of records in batch 198: 0\n",
      "✅ Number of records in batch 198: 0\n",
      "✅ Number of records in batch 199: 0\n",
      "✅ Number of records in batch 199: 1\n",
      "✅ Number of records in batch 200: 0\n",
      "✅ Number of records in batch 200: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/anaconda3/envs/sp3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 52\u001b[0m\n\u001b[1;32m     45\u001b[0m query \u001b[38;5;241m=\u001b[39m streaming_df\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \\\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ✅ Step 8: Keep Streaming Running\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/pyspark/sql/streaming.py:101\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sp3/lib/python3.9/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sp3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, from_json\n",
    "\n",
    "# ✅ Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RealTimeBankingTransactions\") \\\n",
    "    .config(\"spark.sql.streaming.schemaInference\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# ✅ Step 2: Define Explicit JSON Schema (Matches File Structure)\n",
    "schema = StructType([\n",
    "    StructField(\"account_id\", StringType(), True),\n",
    "    StructField(\"transaction_amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_type\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "# ✅ Step 3: Define Input Directory for Streaming JSON Files\n",
    "input_path = \"/home/labuser/Documents/Level3/Day3/StreamingData/\"  # Update if needed\n",
    "\n",
    "# ✅ Step 4: Read Streaming JSON Data\n",
    "streaming_df = spark.readStream \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .load(input_path)\n",
    "\n",
    "# ✅ Step 5: Print Schema for Debugging\n",
    "print(\"✅ Detected Schema:\")\n",
    "streaming_df.printSchema()\n",
    "\n",
    "# ✅ Step 6: Debug If Any Data Is Being Read\n",
    "def check_data_count(df, epoch_id):\n",
    "    count = df.count()\n",
    "    print(f\"✅ Number of records in batch {epoch_id}: {count}\")\n",
    "\n",
    "streaming_df.writeStream \\\n",
    "    .foreachBatch(check_data_count) \\\n",
    "    .start()\n",
    "\n",
    "# ✅ Step 7: Write Output to Console for Debugging\n",
    "query = streaming_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()\n",
    "\n",
    "# ✅ Step 8: Keep Streaming Running\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------------+--------+---------+\n",
      "|account_id|transaction_amount|transaction_type|location|timestamp|\n",
      "+----------+------------------+----------------+--------+---------+\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "|null      |null              |null            |null    |null     |\n",
      "+----------+------------------+----------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- account_id: string (nullable = true)\n",
      " |-- transaction_amount: double (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"account_id\", StringType(), True),\n",
    "    StructField(\"transaction_amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_type\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)  # Kept as String to prevent parsing errors\n",
    "])   \n",
    "    \n",
    "df = spark.read.schema(schema).json(\"/home/labuser/Documents/Level3/Day3/StreamingData/transaction_*.json\")\n",
    "df.show(truncate=False)\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3 ",
   "language": "python",
   "name": "pyspark3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
