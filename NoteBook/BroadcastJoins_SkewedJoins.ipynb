{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/labuser/Documents/Level2_Day2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Lib\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "spark = SparkSession.builder.appName(\"OptimizedJoinsInBanking\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: string (nullable = true)\n",
      " |-- account_type: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- account_id: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- transaction_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Datasets\n",
    "\n",
    "df_account = spark.read.csv(\"/home/labuser/Documents/Level2_Day2/accounts.csv\", header=True, inferSchema=True)\n",
    "df_transactions = spark.read.csv(\"/home/labuser/Documents/Level2_Day2/transactions.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Show Schema \n",
    "\n",
    "df_account.printSchema()\n",
    "df_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "|account_id|transaction_id| amount|transaction_type| timestamp|account_type| balance|customer_name|\n",
      "+----------+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "|  ACC_2878|         TXN_1|4785.79|          Credit|2024-06-06|    Checking|18350.21|Customer_2878|\n",
      "|  ACC_1290|         TXN_2|3225.22|           Debit|2024-04-26|    Business| 4384.69|Customer_1290|\n",
      "|  ACC_5816|         TXN_3| 925.49|           Debit|2024-01-30|    Business|15402.89|Customer_5816|\n",
      "|  ACC_8174|         TXN_4|3362.12|          Credit|2024-06-12|     Savings|10835.49|Customer_8174|\n",
      "|  ACC_5299|         TXN_5|2087.93|           Debit|2024-05-06|    Business|31829.53|Customer_5299|\n",
      "|   ACC_711|         TXN_6|1984.28|          Credit|2024-10-31|     Savings|10962.96| Customer_711|\n",
      "|  ACC_7214|         TXN_7|2609.88|          Credit|2024-10-18|     Savings|29965.25|Customer_7214|\n",
      "|  ACC_2563|         TXN_8|3519.52|           Debit|2024-12-26|    Checking|23893.36|Customer_2563|\n",
      "|  ACC_5182|         TXN_9|2659.26|          Credit|2024-08-15|    Checking|37136.11|Customer_5182|\n",
      "|  ACC_1440|        TXN_10|2831.62|           Debit|2024-02-28|     Savings|10582.88|Customer_1440|\n",
      "|  ACC_5044|        TXN_11|3839.67|           Debit|2024-03-25|     Savings|43631.37|Customer_5044|\n",
      "|  ACC_3219|        TXN_12|3917.45|           Debit|2024-09-09|    Checking| 29059.1|Customer_3219|\n",
      "|  ACC_8746|        TXN_13|  40.81|           Debit|2024-07-28|    Checking|42856.42|Customer_8746|\n",
      "|  ACC_8385|        TXN_14|3625.86|           Debit|2024-09-24|    Checking|12264.59|Customer_8385|\n",
      "|  ACC_1360|        TXN_15|4878.59|          Credit|2024-10-04|    Business|29669.42|Customer_1360|\n",
      "|  ACC_6047|        TXN_16|4266.49|          Credit|2024-02-29|     Savings| 5732.39|Customer_6047|\n",
      "|  ACC_1199|        TXN_17|3442.84|           Debit|2024-05-17|    Business|26410.79|Customer_1199|\n",
      "|  ACC_6050|        TXN_18|3569.94|          Credit|2024-09-16|    Checking| 46150.8|Customer_6050|\n",
      "|  ACC_9741|        TXN_19|1069.52|           Debit|2024-07-07|     Savings|17880.69|Customer_9741|\n",
      "|  ACC_6235|        TXN_20| 293.63|           Debit|2024-07-19|     Savings|18672.68|Customer_6235|\n",
      "+----------+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_optimized_join = df_transactions.join(broadcast(df_account), \"account_id\", \"inner\")\n",
    "df_optimized_join.show()\n",
    "\n",
    "#Why ?\n",
    "Broadcasting the small dataset (accounts) avoids shuffling and speeds up the joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "|account_id|salt|transaction_id| amount|transaction_type| timestamp|account_type| balance|customer_name|\n",
      "+----------+----+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "|  ACC_2878|   0|         TXN_1|4785.79|          Credit|2024-06-06|    Checking|18350.21|Customer_2878|\n",
      "|  ACC_1290|   1|         TXN_2|3225.22|           Debit|2024-04-26|    Business| 4384.69|Customer_1290|\n",
      "|  ACC_5816|   2|         TXN_3| 925.49|           Debit|2024-01-30|    Business|15402.89|Customer_5816|\n",
      "|  ACC_8174|   3|         TXN_4|3362.12|          Credit|2024-06-12|     Savings|10835.49|Customer_8174|\n",
      "|  ACC_5299|   0|         TXN_5|2087.93|           Debit|2024-05-06|    Business|31829.53|Customer_5299|\n",
      "|   ACC_711|   0|         TXN_6|1984.28|          Credit|2024-10-31|     Savings|10962.96| Customer_711|\n",
      "|  ACC_7214|   2|         TXN_7|2609.88|          Credit|2024-10-18|     Savings|29965.25|Customer_7214|\n",
      "|  ACC_2563|   1|         TXN_8|3519.52|           Debit|2024-12-26|    Checking|23893.36|Customer_2563|\n",
      "|  ACC_5182|   1|         TXN_9|2659.26|          Credit|2024-08-15|    Checking|37136.11|Customer_5182|\n",
      "|  ACC_1440|   0|        TXN_10|2831.62|           Debit|2024-02-28|     Savings|10582.88|Customer_1440|\n",
      "|  ACC_5044|   2|        TXN_11|3839.67|           Debit|2024-03-25|     Savings|43631.37|Customer_5044|\n",
      "|  ACC_3219|   4|        TXN_12|3917.45|           Debit|2024-09-09|    Checking| 29059.1|Customer_3219|\n",
      "|  ACC_8746|   3|        TXN_13|  40.81|           Debit|2024-07-28|    Checking|42856.42|Customer_8746|\n",
      "|  ACC_8385|   3|        TXN_14|3625.86|           Debit|2024-09-24|    Checking|12264.59|Customer_8385|\n",
      "|  ACC_1360|   4|        TXN_15|4878.59|          Credit|2024-10-04|    Business|29669.42|Customer_1360|\n",
      "|  ACC_6047|   0|        TXN_16|4266.49|          Credit|2024-02-29|     Savings| 5732.39|Customer_6047|\n",
      "|  ACC_1199|   4|        TXN_17|3442.84|           Debit|2024-05-17|    Business|26410.79|Customer_1199|\n",
      "|  ACC_6050|   2|        TXN_18|3569.94|          Credit|2024-09-16|    Checking| 46150.8|Customer_6050|\n",
      "|  ACC_9741|   4|        TXN_19|1069.52|           Debit|2024-07-07|     Savings|17880.69|Customer_9741|\n",
      "|  ACC_6235|   3|        TXN_20| 293.63|           Debit|2024-07-19|     Savings|18672.68|Customer_6235|\n",
      "+----------+----+--------------+-------+----------------+----------+------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Skewed Join - Optimization(Salting)\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_transactions2 = df_transactions.withColumn(\"salt\", expr(\"floor(rand() * 5)\"))\n",
    "df_account2 = df_account.withColumn(\"salt\", lit(0))\n",
    "\n",
    "df_account2_salted = df_account2.union(df_account.withColumn(\"salt\", lit(1))).union(df_account.withColumn(\"salt\", lit(2))).union(df_account.withColumn(\"salt\", lit(3))).union(df_account.withColumn(\"salt\", lit(4)))\n",
    "\n",
    "df_skewed_join = df_transactions2.join(df_account2_salted, [\"account_id\", \"salt\"], \"inner\")\n",
    "\n",
    "df_skewed_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, floor, rand, lit, monotonically_increasing_id\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SkewedJoinOptimization\").getOrCreate()\n",
    "\n",
    "# 1️⃣ Sample Data - Banking Transactions (Skewed Data)\n",
    "data_transactions = [\n",
    "    (101, \"John Doe\", \"Credit\", 500),\n",
    "    (102, \"Jane Smith\", \"Debit\", 200),\n",
    "    (101, \"John Doe\", \"Credit\", 1000),  # Account 101 appears multiple times (skewed)\n",
    "    (103, \"Alice Brown\", \"Credit\", 700),\n",
    "    (101, \"John Doe\", \"Debit\", 300),  # Skewed Key\n",
    "    (102, \"Jane Smith\", \"Credit\", 600),\n",
    "]\n",
    "\n",
    "data_accounts = [\n",
    "    (101, \"John Doe\", \"Savings\"),\n",
    "    (102, \"Jane Smith\", \"Checking\"),\n",
    "    (103, \"Alice Brown\", \"Savings\"),\n",
    "]\n",
    "\n",
    "# 2️⃣ Creating DataFrames\n",
    "columns_transactions = [\"account_id\", \"customer_name\", \"transaction_type\", \"amount\"]\n",
    "df_transactions = spark.createDataFrame(data_transactions, columns_transactions)\n",
    "\n",
    "columns_accounts = [\"account_id\", \"customer_name\", \"account_type\"]\n",
    "df_accounts = spark.createDataFrame(data_accounts, columns_accounts)\n",
    "\n",
    "# ✅ Adding Unique Transaction IDs using `monotonically_increasing_id`\n",
    "df_transactions = df_transactions.withColumn(\"transaction_id\", monotonically_increasing_id())\n",
    "\n",
    "# ✅ Skewed Join Optimization (Salting)\n",
    "# Add Salt Key to Transactions (random number between 0 and 4)\n",
    "df_transactions = df_transactions.withColumn(\"salt\", expr(\"floor(rand() * 5)\"))\n",
    "\n",
    "# Duplicate `df_accounts` 5 times, each with a different salt value\n",
    "df_accounts_salted = df_accounts.union(df_accounts.withColumn(\"salt\", lit(1)))\\\n",
    "                                 .union(df_accounts.withColumn(\"salt\", lit(2)))\\\n",
    "                                 .union(df_accounts.withColumn(\"salt\", lit(3)))\\\n",
    "                                 .union(df_accounts.withColumn(\"salt\", lit(4)))\n",
    "\n",
    "# ✅ Perform Skewed Join with Salting\n",
    "df_skewed_join = df_transactions.join(df_accounts_salted, [\"account_id\", \"salt\"], \"inner\")\n",
    "\n",
    "# ✅ Show Results\n",
    "df_skewed_join.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3 ",
   "language": "python",
   "name": "pyspark3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
